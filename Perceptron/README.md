# ğŸ§  Perceptron Algorithm â€“ From Scratch & Scikit-Learn

This folder is part of my **Deep Learning Journey**, where I explored the foundational **Perceptron algorithm**, implemented both from scratch and using Scikit-Learn.

---

## ğŸ“˜ What You'll Find Here

### âœ… `Scikit-Learn_Perceptron.ipynb`
- Uses Scikit-Learnâ€™s `Perceptron` class from `sklearn.linear_model`
- Demonstrates training and evaluation with built-in tools
- Shows how libraries simplify model training

### âœ… `Perceptron_Code.ipynb` (From Scratch)
- Implements the **Perceptron algorithm** manually using Python and NumPy
- Step-by-step logic for forward pass and weight updates
- Includes custom training loop with learning rate and epoch control

---

## ğŸ“š What I Learned
- How the **Perceptron algorithm** works and its significance in deep learning
- How weights are updated using the rule:  
  \[
  w = w + \text{learning_rate} \times (y_{\text{true}} - y_{\text{pred}}) \times x
  \]
- How linearly separable data can be classified with Perceptrons
- Hands-on difference between manual implementation and using Scikit-Learn

---

## ğŸš€ Why This Matters
Understanding the **Perceptron** is essential because:
- It is one of the earliest neural network models
- It introduces core concepts like:
  - Activation functions
  - Weight updates
  - Supervised learning
- It serves as a building block for more complex models like **MLPs (Multi-Layer Perceptrons)**

---

## âœï¸ Blog Post
ğŸ‘‰ I also wrote a detailed blog post about Perceptron on Medium:
[ğŸ“– Read my blog on Perceptron](https://medium.com/@divyanshu1331/week-1-learning-the-perceptron-from-intuition-to-code-c03033fcba31)

Stay tuned!
