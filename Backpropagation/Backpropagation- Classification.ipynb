{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ddbde34-19bf-43a3-a103-092b5c76d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b5071c-b14f-44a7-909f-88992d0ca83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Creating a small dataset of 6 samples with 2 features and 1 o/p\n",
    "\n",
    "# Features:\n",
    "x1 = [0.5, 1.5, 3.0, 2.0, 0.1, 4.0]\n",
    "x2 = [1.0, 2.0, 1.0, 3.0, 0.5, 2.0]\n",
    "\n",
    "# Output:\n",
    "y =  []\n",
    "for i in range(6):\n",
    "\n",
    "    sum = x1[i] + x2[i]\n",
    "    if sum>3:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21151b26-475a-4755-98ef-ebe29c2a78e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature1  Feature2  y\n",
       "0       0.5       1.0  0\n",
       "1       1.5       2.0  1\n",
       "2       3.0       1.0  1\n",
       "3       2.0       3.0  1\n",
       "4       0.1       0.5  0\n",
       "5       4.0       2.0  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe of the features and output\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Feature1' : x1,\n",
    "    'Feature2' : x2,\n",
    "    'y' : y\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29218f0-1a53-4f0e-9af1-eb1a3dafbfb6",
   "metadata": {},
   "source": [
    "### ðŸ§  Neural Network Architecture:\n",
    "\n",
    "- **Problem Type:** Classification  \n",
    "- **Input Features:** 2 (`x1`, `x2`)  \n",
    "- **Architecture:**\n",
    "  - **Input Layer:** 2 neurons (for 2 input features)\n",
    "  - **Hidden Layer:** 2 neurons  \n",
    "  - **Output Layer:** 1 neuron  \n",
    "- **Activation Function:**  \n",
    "  - Hidden Layer: `Sigmoid`  \n",
    "  - Output Layer: `Sigmoid`  \n",
    "- **Loss Function:** Binary Cross Entropy \n",
    "- **Optimization Algorithm:** Gradient Descent (Manually implemented)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab126405-68a2-4c80-9949-09ce5e9cb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intializing parameters:\n",
    "\n",
    "def initialize_param(layer_dim):         # i.e- Layer_dim = [2,2,1] means 2 i/p neurons, 2 neurons in hidden layer 1, 1 neuron in o/p layer\n",
    "    \n",
    "    params = {}                       # A dictionary to store parameters (weight and bias)     \n",
    "\n",
    "    L = len(layer_dim)\n",
    "    \n",
    "    for i in (1, L-1):\n",
    "\n",
    "        # Weight matrix: number of rows: layer_dim[i-1] (number of neurons in the previous layer)\n",
    "        # number of columns: layer_dim[i] (number of neurons in the current layer)\n",
    "        params['w' + str(i)] = np.ones((layer_dim[i-1], layer_dim[i])) * 0.1    # np.ones((shape)): np.ones((2,3)) gives a matrix of 1 of size {2,3}\n",
    "                                                                                # & np.ones(...) * 0.1 means all values in this matrix are 0.1\n",
    "        params['b' + str(i)] = np.zeros((layer_dim[i], 1))                      # it gives a column matrix (shape: {rows, 1}) of 0 \n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f15153-dd7e-477c-b5e1-0c907c96ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w1': array([[0.1, 0.1],\n",
      "       [0.1, 0.1]]), 'b1': array([[0.],\n",
      "       [0.]]), 'w2': array([[0.1],\n",
      "       [0.1]]), 'b2': array([[0.]])}\n"
     ]
    }
   ],
   "source": [
    "# Initializing parameters for the neural n/w:\n",
    "\n",
    "layer_dim = [2,2,1]\n",
    "\n",
    "params = initialize_param(layer_dim)\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63309b5-1e32-4cb4-ad3d-fdc0e5792440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "\n",
    "def sigmoid(z):\n",
    "\n",
    "    val = 1/(1 + np.exp(-z))\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbaba29e-1c08-4809-b577-954be76d7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation for one sample (Calculates layer-wise o/p for one sample)\n",
    "\n",
    "def forward_pass(x, params, layer_dim):\n",
    "\n",
    "    layer_output = {}\n",
    "    \n",
    "    layer_count = len(layer_dim)\n",
    "    \n",
    "    # Output for first layer:\n",
    "    z = np.dot(params['w1'].T , x) + params['b1']\n",
    "    layer_output['l' + str(1)] = sigmoid(z)                # Applying activation function to the weighted sum(z)\n",
    "    \n",
    "    for i in range(2, layer_count):                        # loop from 2nd layer to last layer- [2, last_layer + 1), last_layer + 1 means layer_count\n",
    "\n",
    "        layer_w = params['w' + str(i)]\n",
    "        layer_b = params['b' + str(i)]\n",
    "        A_prev  = layer_output['l' + str(i-1)]\n",
    "        \n",
    "        z = np.dot(layer_w.T , A_prev) + layer_b\n",
    "        layer_output['l' + str(i)] = sigmoid(z)\n",
    "\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b54de7e-d8e5-447b-8cd0-6477d4a60b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function(Binary Cross Entropy) for 1 sample:\n",
    "\n",
    "def loss(y, y_hat):\n",
    "\n",
    "    loss = (-1)*( y*np.log(y_hat) + (1-y)*(np.log(1-y_hat)))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b317fd-f5f3-4350-bafe-0b6eb0536eb5",
   "metadata": {},
   "source": [
    "### âœ… All 9 Gradients of this Neural Network are:\n",
    "\n",
    "| Gradient                           | Formula                                                                 |\n",
    "|------------------------------------|-------------------------------------------------------------------------|\n",
    "| $\\frac{\\partial L}{\\partial W^{[2]}_{11}}$ | $-(y - \\hat{y}) \\cdot o_{11}$                                                  |\n",
    "| $\\frac{\\partial L}{\\partial W^{[2]}_{21}}$ | $-(y - \\hat{y}) \\cdot o_{12}$                                                  |\n",
    "| $\\frac{\\partial L}{\\partial b_{21}}$       | $-(y - \\hat{y})$                                                             |\n",
    "| $\\frac{\\partial L}{\\partial W^{[1]}_{11}}$ | $-(y - \\hat{y}) \\cdot W^{[2]}_{11} \\cdot o_{11}(1 - o_{11}) \\cdot x_1$        |\n",
    "| $\\frac{\\partial L}{\\partial W^{[1]}_{12}}$ | $-(y - \\hat{y}) \\cdot W^{[2]}_{21} \\cdot o_{12}(1 - o_{12}) \\cdot x_1$        |\n",
    "| $\\frac{\\partial L}{\\partial W^{[1]}_{21}}$ | $-(y - \\hat{y}) \\cdot W^{[2]}_{11} \\cdot o_{11}(1 - o_{11}) \\cdot x_2$        |\n",
    "| $\\frac{\\partial L}{\\partial W^{[1]}_{22}}$ | $-(y - \\hat{y}) \\cdot W^{[2]}_{21} \\cdot o_{12}(1 - o_{12}) \\cdot x_2$        |\n",
    "| $\\frac{\\partial L}{\\partial b_{11}}$       | $-(y - \\hat{y}) \\cdot W^{[2]}_{11} \\cdot o_{11}(1 - o_{11})$                 |\n",
    "| $\\frac{\\partial L}{\\partial b_{12}}$       | $-(y - \\hat{y}) \\cdot W^{[2]}_{21} \\cdot o_{12}(1 - o_{12})$                 |\n",
    "\n",
    "ðŸ”¹ Where:\n",
    "- $\\hat{y} = o_{21}$ : predicted output (after sigmoid)  \n",
    "- $y$ : true label (0 or 1)  \n",
    "- $o_{11}, o_{12}$ : outputs from hidden layer neurons  \n",
    "- $x_1, x_2$ : input features\n",
    "\n",
    "---\n",
    "### âœ… Gradient Descent Formula\n",
    "\n",
    "For any parameter $\\theta$:\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\alpha \\cdot \\frac{\\partial L}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\alpha$: learning rate (let's take it as 0.001)\n",
    "- $\\frac{\\partial L}{\\partial \\theta}$: gradient of loss with respect to that parameter\n",
    "\n",
    "---\n",
    "### âœ… Parameter Update Formulas, by substituting Gradient value in Gradient Descent formula (In Same Order as Code)\n",
    "\n",
    "| Python Code Line             | Parameters             | Update Formula                                                                                      |\n",
    "|------------------------------|------------------------|------------------------------------------------------------------------------------------------------|\n",
    "| `parameters['W2'][0][0]`     | $W^{[2]}_{11}$         | $ W^{[2]}_{11} = W^{[2]}_{11} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot o_{11}]$                          |\n",
    "| `parameters['W2'][1][0]`     | $W^{[2]}_{21}$         | $ W^{[2]}_{21} = W^{[2]}_{21} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot o_{12}]$                          |\n",
    "| `parameters['b2'][0][0]`     | $b_{21}$               | $ b_{21} = b_{21} - \\alpha \\cdot [-(y - \\hat{y})]$                                                   |\n",
    "| `parameters['W1'][0][0]`     | $W^{[1]}_{11}$         | $ W^{[1]}_{11} = W^{[1]}_{11} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot W^{[2]}_{11} \\cdot o_{11}(1 - o_{11}) \\cdot x_1]$ |\n",
    "| `parameters['W1'][0][1]`     | $W^{[1]}_{12}$         | $ W^{[1]}_{12} = W^{[1]}_{12} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot W^{[2]}_{21} \\cdot o_{12}(1 - o_{12}) \\cdot x_1]$ |\n",
    "| `parameters['W1'][1][0]`     | $W^{[1]}_{21}$         | $ W^{[1]}_{21} = W^{[1]}_{21} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot W^{[2]}_{11} \\cdot o_{11}(1 - o_{11}) \\cdot x_2]$ |\n",
    "| `parameters['W1'][1][1]`     | $W^{[1]}_{22}$         | $ W^{[1]}_{22} = W^{[1]}_{22} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot W^{[2]}_{21} \\cdot o_{12}(1 - o_{12}) \\cdot x_2]$ |\n",
    "| `parameters['b1'][0][0]`     | $b_{11}$               | $ b_{11} = b_{11} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot W^{[2]}_{11} \\cdot o_{11}(1 - o_{11})]$        |\n",
    "| `parameters['b1'][1][0]`     | $b_{12}$               | $ b_{12} = b_{12} - \\alpha \\cdot [-(y - \\hat{y}) \\cdot W^{[2]}_{21} \\cdot o_{12}(1 - o_{12})]$        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25fe34f-e631-4f50-ab6d-395a7f74721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameter value by gradient descent algorithm for 1 sample:\n",
    "\n",
    "def update_parameters(params, y, layer_output, X):\n",
    "\n",
    "    y_hat = layer_output['l2']              # output from layer 2\n",
    "    A1 = layer_output['l1']                 # Output from layer 1\n",
    "\n",
    "    lr = 0.001\n",
    "    error = (y - y_hat).item()              # convert to scalar\n",
    "    \n",
    "    w211 = params['w2'][0][0].item()\n",
    "    w221 = params['w2'][1][0].item()\n",
    "\n",
    "    a11 = A1[0][0].item()                   # o11\n",
    "    a12 = A1[1][0].item()                   # o12\n",
    "\n",
    "    x1 = X[0][0].item()\n",
    "    x2 = X[1][0].item()\n",
    "\n",
    "    # Update output layer weights and bias\n",
    "    params['w2'][0][0] += lr * error * a11    # W[2]11\n",
    "    params['w2'][1][0] += lr * error * a12    # W[2]21\n",
    "    params['b2'][0][0] += lr * error          # b21\n",
    "\n",
    "    # Update first hidden layer weights and biases\n",
    "    params['w1'][0][0] += lr * error * w211 * a11*(1-a11) * x1   # W[1]11\n",
    "    params['w1'][1][0] += lr * error * w211 * a11*(1-a11) * x2   # W[1]21\n",
    "    params['b1'][0][0] += lr * error * w211 * a11*(1-a11)        # b11\n",
    "    \n",
    "    params['w1'][0][1] += lr * error * w221 * a12*(1-a12) * x1   # W[1]12\n",
    "    params['w1'][1][1] += lr * error * w221 * a12*(1-a12) * x2   # W[1]22\n",
    "    params['b1'][1][0] += lr * error * w221 * a12*(1-a12)        # b12\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0462cdb-34fe-4341-b7e4-d6e00c91e3c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658b539-d93f-4614-8d9d-b3081498da75",
   "metadata": {},
   "source": [
    "## Predicting output and updating parameter for 1st sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40afa8c9-e0e9-4220-89f0-cd0a2d0e883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]\n",
      " [1. ]]\n",
      "0\n",
      "{'w1': array([[0.1, 0.1],\n",
      "       [0.1, 0.1]]), 'b1': array([[0.],\n",
      "       [0.]]), 'w2': array([[0.1],\n",
      "       [0.1]]), 'b2': array([[0.]])}\n"
     ]
    }
   ],
   "source": [
    "# Creating x(features) and y(target) array for 1st input sample:\n",
    "\n",
    "x = df[['Feature1', 'Feature2']].values[0].reshape(2,1)      # Shape(no of features, no. of training example)\n",
    "y = df[['y']].values[0][0]\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7ef802-97d7-4620-9ddf-c84fc7cb50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1': array([[0.53742985],\n",
      "       [0.53742985]]), 'l2': array([[0.52684565]])}\n"
     ]
    }
   ],
   "source": [
    "# Prediction for 1st input sample:\n",
    "\n",
    "y1_hat = forward_pass(x, params, layer_dim)\n",
    "\n",
    "print(y1_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e980900d-da60-4440-b0ea-5d3373807e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483336246288533\n"
     ]
    }
   ],
   "source": [
    "# Loss of 1st sample:\n",
    "\n",
    "print(loss(y , y1_hat['l2']).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc19432-d007-4173-934c-d6a721927b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w1': array([[0.09999345, 0.09999345],\n",
      "       [0.0999869 , 0.0999869 ]]), 'b1': array([[-1.30973306e-05],\n",
      "       [-1.30973306e-05]]), 'w2': array([[0.09971686],\n",
      "       [0.09971686]]), 'b2': array([[-0.00052685]])}\n"
     ]
    }
   ],
   "source": [
    "# Updating parmaters for 1st input sample:\n",
    "\n",
    "update_parameters(params, y, y1_hat, x)\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1513b576-c5a0-4356-9902-581cde04c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted o/p after paramter update:\n",
      " {'l1': array([[0.53742252],\n",
      "       [0.53742252]]), 'l2': array([[0.52663809]])}\n",
      "Loss after paramter update:\n",
      " 0.7478950355194686\n"
     ]
    }
   ],
   "source": [
    "# Checking loss after parameter update for 1st sample:\n",
    "\n",
    "y1_new = forward_pass(x, params, layer_dim)\n",
    "print('Predicted o/p after paramter update:\\n', y1_new)\n",
    "print('Loss after paramter update:\\n', loss(y, y1_new['l2']).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e62425-e386-4738-a39f-175ebd0c7e8a",
   "metadata": {},
   "source": [
    "## Predicting output and updating parameter for 2nd sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb63ff86-ea62-433f-a158-11ce931b62e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[1.5]\n",
      " [2. ]]\n",
      "Y:\n",
      " 1\n",
      "Initial Paramters:\n",
      " {'w1': array([[0.09999345, 0.09999345],\n",
      "       [0.0999869 , 0.0999869 ]]), 'b1': array([[-1.30973306e-05],\n",
      "       [-1.30973306e-05]]), 'w2': array([[0.09971686],\n",
      "       [0.09971686]]), 'b2': array([[-0.00052685]])}\n",
      "Output of layers:\n",
      " {'l1': array([[0.58660567],\n",
      "       [0.58660567]]), 'l2': array([[0.52908266]])}\n",
      "Loss:  0.636610599922258\n",
      "Updated paramters:\n",
      " {'w1': array([[0.10001053, 0.10001053],\n",
      "       [0.10000968, 0.10000968]]), 'b1': array([[-1.70994469e-06],\n",
      "       [-1.70994469e-06]]), 'w2': array([[0.0999931],\n",
      "       [0.0999931]]), 'b2': array([[-5.59283123e-05]])}\n",
      "Predicted o/p after paramter update:\n",
      " {'l1': array([[0.58662569],\n",
      "       [0.58662569]]), 'l2': array([[0.52928173]])}\n",
      "Loss after paramter update:\n",
      " 0.6362344107188425\n"
     ]
    }
   ],
   "source": [
    "x = df[['Feature1', 'Feature2']].values[1].reshape(2,1)      \n",
    "y = df[['y']].values[1][0]\n",
    "\n",
    "print('X:\\n', x)\n",
    "print('Y:\\n', y)\n",
    "print('Initial Paramters:\\n', params)\n",
    "\n",
    "# output prediction of layers\n",
    "y2_hat = forward_pass(x, params, layer_dim)\n",
    "print('Output of layers:\\n', y2_hat)\n",
    "\n",
    "# Loss\n",
    "print('Loss: ', loss(y, y2_hat['l2']).item())\n",
    "\n",
    "# Paramters update\n",
    "update_parameters(params, y, y2_hat, x)\n",
    "print('Updated paramters:\\n', params)\n",
    "\n",
    "# Checking loss after parameter update:\n",
    "y2_new = forward_pass(x, params, layer_dim)\n",
    "print('Predicted o/p after paramter update:\\n', y2_new)\n",
    "print('Loss after paramter update:\\n', loss(y, y2_new['l2']).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c2f34-206d-4c1b-adf2-ce89af234f9c",
   "metadata": {},
   "source": [
    "## Predicting output and updating parameter for 3rd sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc18d94a-1d12-4d7c-a84e-bf37df141a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[3.]\n",
      " [1.]]\n",
      "Y:\n",
      " 1\n",
      "Initial Paramters:\n",
      " {'w1': array([[0.10001053, 0.10001053],\n",
      "       [0.10000968, 0.10000968]]), 'b1': array([[-1.70994469e-06],\n",
      "       [-1.70994469e-06]]), 'w2': array([[0.0999931],\n",
      "       [0.0999931]]), 'b2': array([[-5.59283123e-05]])}\n",
      "Output of layers:\n",
      " {'l1': array([[0.59869717],\n",
      "       [0.59869717]]), 'l2': array([[0.52988315]])}\n",
      "Loss:  0.6350987621509052\n",
      "Updated paramters:\n",
      " {'w1': array([[0.10004441, 0.10004441],\n",
      "       [0.10002097, 0.10002097]]), 'b1': array([[9.58425019e-06],\n",
      "       [9.58425019e-06]]), 'w2': array([[0.10027456],\n",
      "       [0.10027456]]), 'b2': array([[0.00041419]])}\n",
      "Predicted o/p after paramter update:\n",
      " {'l1': array([[0.59872701],\n",
      "       [0.59872701]]), 'l2': array([[0.5300857]])}\n",
      "Loss after paramter update:\n",
      " 0.6347165837031522\n"
     ]
    }
   ],
   "source": [
    "x = df[['Feature1', 'Feature2']].values[2].reshape(2,1)      \n",
    "y = df[['y']].values[2][0]\n",
    "\n",
    "print('X:\\n', x)\n",
    "print('Y:\\n', y)\n",
    "print('Initial Paramters:\\n', params)\n",
    "\n",
    "# output prediction of layers\n",
    "y3_hat = forward_pass(x, params, layer_dim)\n",
    "print('Output of layers:\\n', y3_hat)\n",
    "\n",
    "# Loss\n",
    "print('Loss: ', loss(y, y3_hat['l2']).item())\n",
    "\n",
    "# Paramters update\n",
    "update_parameters(params, y, y3_hat, x)\n",
    "print('Updated paramters:\\n', params)\n",
    "\n",
    "# Checking loss after parameter update:\n",
    "y3_new = forward_pass(x, params, layer_dim)\n",
    "print('Predicted o/p after paramter update:\\n', y3_new)\n",
    "print('Loss after paramter update:\\n', loss(y, y3_new['l2']).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bac9e5-ddcc-4340-b28a-04977f618942",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "260a9151-27bb-4bb2-8799-1ceb58949cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 :\n",
      "Parameters: {'w1': array([[0.10015275, 0.10015275],\n",
      "       [0.10009007, 0.10009007]]), 'b1': array([[2.77479323e-05],\n",
      "       [2.77479323e-05]]), 'w2': array([[0.1008713],\n",
      "       [0.1008713]]), 'b2': array([[0.00123748]])}\n",
      "Sample loss: [0.7487087651614454, 0.6362613759815511, 0.6347461323725118, 0.6321218418316483, 0.7471115857934999, 0.6299477926944006]\n",
      "Epoch Loss:  0.6714829156391762\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  1 :\n",
      "Parameters: {'w1': array([[0.10026161, 0.10026161],\n",
      "       [0.10015948, 0.10015948]]), 'b1': array([[4.5959641e-05],\n",
      "       [4.5959641e-05]]), 'w2': array([[0.10146687],\n",
      "       [0.10146687]]), 'b2': array([[0.00205847]])}\n",
      "Sample loss: [0.7494847148744956, 0.6355375199886034, 0.6340149291475079, 0.63137931072389, 0.7478690592246311, 0.6291917830206483]\n",
      "Epoch Loss:  0.6712462194966293\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  2 :\n",
      "Parameters: {'w1': array([[0.100371 , 0.100371 ],\n",
      "       [0.1002292, 0.1002292]]), 'b1': array([[6.42185669e-05],\n",
      "       [6.42185669e-05]]), 'w2': array([[0.10206126],\n",
      "       [0.10206126]]), 'b2': array([[0.00287718]])}\n",
      "Sample loss: [0.7502593868567423, 0.6348158603230839, 0.6332859114143201, 0.6306390015927548, 0.748625230870963, 0.6284379931328212]\n",
      "Epoch Loss:  0.6710105640317808\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  3 :\n",
      "Parameters: {'w1': array([[0.10048091, 0.10048091],\n",
      "       [0.10029923, 0.10029923]]), 'b1': array([[8.25239053e-05],\n",
      "       [8.25239053e-05]]), 'w2': array([[0.10265448],\n",
      "       [0.10265448]]), 'b2': array([[0.0036936]])}\n",
      "Sample loss: [0.75103278213209, 0.6340963884508868, 0.6325590705558859, 0.6299009056611082, 0.749380101690384, 0.6276864141110381]\n",
      "Epoch Loss:  0.6707759437668988\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  4 :\n",
      "Parameters: {'w1': array([[0.10059133, 0.10059133],\n",
      "       [0.10036957, 0.10036957]]), 'b1': array([[0.00010087],\n",
      "       [0.00010087]]), 'w2': array([[0.10324654],\n",
      "       [0.10324654]]), 'b2': array([[0.00450775]])}\n",
      "Sample loss: [0.7518049017296674, 0.633379095879891, 0.6318343979988303, 0.6291650141968076, 0.7501336726470836, 0.6269370370832026]\n",
      "Epoch Loss:  0.6705423532559139\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  5 :\n",
      "Parameters: {'w1': array([[0.10070227, 0.10070227],\n",
      "       [0.10044021, 0.10044021]]), 'b1': array([[0.00011927],\n",
      "       [0.00011927]]), 'w2': array([[0.10383743],\n",
      "       [0.10383743]]), 'b2': array([[0.00531962]])}\n",
      "Sample loss: [0.7525757466837779, 0.6326639741597113, 0.6311118852131977, 0.6284313185124206, 0.7508859447114942, 0.6261898532246897]\n",
      "Epoch Loss:  0.6703097870842152\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  6 :\n",
      "Parameters: {'w1': array([[0.10081373, 0.10081373],\n",
      "       [0.10051116, 0.10051116]]), 'b1': array([[0.00013771],\n",
      "       [0.00013771]]), 'w2': array([[0.10442716],\n",
      "       [0.10442716]]), 'b2': array([[0.00612923]])}\n",
      "Sample loss: [0.7533453180338473, 0.6319510148814516, 0.630391523712185, 0.6276998099649465, 0.7516369188602346, 0.6254448537580348]\n",
      "Epoch Loss:  0.67007823986845\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  7 :\n",
      "Parameters: {'w1': array([[0.10092569, 0.10092569],\n",
      "       [0.1005824 , 0.1005824 ]]), 'b1': array([[0.00015619],\n",
      "       [0.00015619]]), 'w2': array([[0.10501574],\n",
      "       [0.10501574]]), 'b2': array([[0.00693657]])}\n",
      "Sample loss: [0.7541136168243757, 0.6312402096774593, 0.6296733050518782, 0.6269704799555388, 0.7523865960760538, 0.6247020299526261]\n",
      "Epoch Loss:  0.6698477062563221\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  8 :\n",
      "Parameters: {'w1': array([[0.10103817, 0.10103817],\n",
      "       [0.10065395, 0.10065395]]), 'b1': array([[0.00017472],\n",
      "       [0.00017472]]), 'w2': array([[0.10560317],\n",
      "       [0.10560317]]), 'b2': array([[0.00774165]])}\n",
      "Sample loss: [0.7548806441048861, 0.6305315502210825, 0.6289572208309887, 0.626243319929231, 0.7531349773477741, 0.6239613731243968]\n",
      "Epoch Loss:  0.6696181809263932\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch  9 :\n",
      "Parameters: {'w1': array([[0.10115115, 0.10115115],\n",
      "       [0.1007258 , 0.1007258 ]]), 'b1': array([[0.00019329],\n",
      "       [0.00019329]]), 'w2': array([[0.10618944],\n",
      "       [0.10618944]]), 'b2': array([[0.00854448]])}\n",
      "Sample loss: [0.7556464009298756, 0.6298250282264287, 0.6282432626905938, 0.6255183213746623, 0.7538820636702365, 0.6232228746355228]\n",
      "Epoch Loss:  0.6693896585878867\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Epoch Implementation:\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    sample_loss = []\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "\n",
    "        x = df[['Feature1', 'Feature2']].values[i].reshape(2,1)\n",
    "        y = df[['y']].values[i][0]\n",
    "        \n",
    "        y_hat = forward_pass(x, params, layer_dim)\n",
    "        \n",
    "        sample_loss.append(loss(y, y_hat['l2']).item())\n",
    "        \n",
    "        update_parameters(params, y, y_hat, x)\n",
    "\n",
    "    print('Epoch ', str(j), ':')\n",
    "    print('Parameters:', params)\n",
    "    print('Sample loss:', sample_loss)\n",
    "    print('Epoch Loss: ', np.mean(sample_loss))\n",
    "    print('------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755328d7-bc30-4532-8e5a-473819a1dd59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
